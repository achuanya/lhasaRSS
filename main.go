package main

import (
    // -------------------- å¼•å…¥æ‰€éœ€åŒ… --------------------
    "context"
    "encoding/base64"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "net/url"
    "os"
    "path/filepath"
    "regexp"
    "sort"
    "strings"
    "sync"
    "time"

    "github.com/mmcdole/gofeed"
    "github.com/tencentyun/cos-go-sdk-v5"
    "golang.org/x/net/html"
)

/* ==================== æ•°æ®ç»“æ„å®šä¹‰ ==================== */

// Article ç»“æ„ä½“ï¼šåªä¿ç•™æœ€å…³é”®çš„å­—æ®µ
type Article struct {
    BlogName  string `json:"blog_name"` // åšå®¢åç§°
    Title     string `json:"title"`     // æ–‡ç« æ ‡é¢˜
    Published string `json:"published"` // æ–‡ç« å‘å¸ƒæ—¶é—´ (å·²æ ¼å¼åŒ–ä¸º "09 Mar 2025")
    Link      string `json:"link"`      // æ–‡ç« é“¾æ¥
    Avatar    string `json:"avatar"`    // åšå®¢å¤´åƒ
}

// AllData ç»“æ„ä½“ï¼šç”¨äºæœ€ç»ˆè¾“å‡º JSON
type AllData struct {
    Items   []Article `json:"items"`   // æ‰€æœ‰æ–‡ç« 
    Updated string    `json:"updated"` // æ•°æ®æ›´æ–°æ—¶é—´ï¼ˆç”¨ä¸­æ–‡æ ¼å¼å­—ç¬¦ä¸²ï¼‰
}

// feedResult ç”¨äºå¹¶å‘æŠ“å–æ—¶ï¼Œä¿å­˜å•ä¸ª RSS feed çš„æŠ“å–ç»“æœï¼ˆæˆ–é”™è¯¯ä¿¡æ¯ï¼‰
type feedResult struct {
    Article    *Article  // æŠ“åˆ°çš„æœ€æ–°ä¸€ç¯‡æ–‡ç« ï¼ˆå¯èƒ½ä¸º nilï¼‰
    FeedLink   string    // RSS åœ°å€
    Err        error     // æŠ“å–è¿‡ç¨‹ä¸­çš„é”™è¯¯
    ParsedTime time.Time // æ­£ç¡®è§£æåˆ°çš„å‘å¸ƒæ—¶é—´ï¼Œç”¨äºåç»­æ’åº
}

/* ==================== æ—¶é—´è§£æç›¸å…³å‡½æ•° ==================== */

// parseTime å°è¯•ç”¨å¤šç§æ ¼å¼è§£æ RSS ä¸­çš„æ—¶é—´å­—ç¬¦ä¸²ï¼Œè‹¥éƒ½å¤±è´¥åˆ™è¿”å›é”™è¯¯
func parseTime(timeStr string) (time.Time, error) {
    // å®šä¹‰å¯èƒ½å‡ºç°çš„å¤šç§æ—¶é—´æ ¼å¼
    formats := []string{
        time.RFC1123Z,                   // "Mon, 02 Jan 2006 15:04:05 -0700"
        time.RFC1123,                    // "Mon, 02 Jan 2006 15:04:05 MST"
        time.RFC3339,                    // "2006-01-02T15:04:05Z07:00"
        "2006-01-02T15:04:05.000Z07:00", // "2025-02-09T13:20:27.000Z"
        "Mon, 02 Jan 2006 15:04:05 +0000",
    }

    // ä¾æ¬¡å°è¯•è§£æ
    for _, f := range formats {
        if t, err := time.Parse(f, timeStr); err == nil {
            return t, nil
        }
    }
    // å¦‚æœéƒ½å¤±è´¥ï¼Œå°±è¿”å›é”™è¯¯
    return time.Time{}, fmt.Errorf("æ— æ³•è§£ææ—¶é—´: %s", timeStr)
}

/* ==================== å¤´åƒå¤„ç†ç›¸å…³å‡½æ•° ==================== */

// getFeedAvatarURL å°è¯•ä» feed.Image æˆ–è€…åšå®¢ä¸»é¡µè·å–å¤´åƒåœ°å€
func getFeedAvatarURL(feed *gofeed.Feed) string {
    // å¦‚æœ RSS ä¸­å­˜åœ¨ <image> æ ‡ç­¾ä¸” URL ä¸ä¸ºç©ºï¼Œåˆ™ä¼˜å…ˆä½¿ç”¨
    if feed.Image != nil && feed.Image.URL != "" {
        return feed.Image.URL
    }
    // å¦åˆ™ï¼Œå¦‚æœ feed.Link ä¸ä¸ºç©ºï¼Œå°±å°è¯•è®¿é—®è¯¥é“¾æ¥è·å–å¤´åƒ
    if feed.Link != "" {
        return fetchBlogLogo(feed.Link)
    }
    // å¦‚æœä»¥ä¸Šéƒ½ä¸è¡Œï¼Œå°±è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œåç»­å†åšé»˜è®¤å¤´åƒå¤„ç†
    return ""
}

// fetchBlogLogo å°è¯•æŠ“å–åšå®¢ä¸»é¡µçš„ HTMLï¼Œå¹¶ä» <head> ä¸­è·å–æœ€å¸¸è§çš„ iconï¼›è‹¥æ²¡æœ‰åˆ™ fallback åˆ° favicon.ico
func fetchBlogLogo(blogURL string) string {
    // 1. è¯·æ±‚åšå®¢ä¸»é¡µ
    resp, err := http.Get(blogURL)
    if err != nil {
        // å¦‚æœè¯·æ±‚å¤±è´¥ï¼Œç›´æ¥é€€å›åˆ° fallbackFavicon
        return fallbackFavicon(blogURL)
    }
    defer resp.Body.Close()

    // å¦‚æœå“åº”çŠ¶æ€ä¸æ˜¯ 200ï¼Œåˆ™ä¹Ÿä½¿ç”¨ fallback
    if resp.StatusCode != 200 {
        return fallbackFavicon(blogURL)
    }

    // 2. è§£æ HTMLï¼Œå¯»æ‰¾ <link rel="icon"> / <link rel="shortcut icon"> / <link rel="apple-touch-icon"> / <meta property="og:image">
    doc, err := html.Parse(resp.Body)
    if err != nil {
        return fallbackFavicon(blogURL)
    }

    // ç”¨äºå­˜å‚¨è§£æåˆ°çš„ icon å’Œ og:image
    var iconHref string
   [thinking]

 var ogImage string

    // é€’å½’å‡½æ•°ï¼Œéå†æ•´æ£µ DOM æ ‘
    var f func(*html.Node)
    f = func(n *html.Node) {
        if n.Type == html.ElementNode {
            tagName := strings.ToLower(n.Data)
            // å¤„ç† <link ...> æ ‡ç­¾
            if tagName == "link" {
                var relVal, hrefVal string
                for _, attr := range n.Attr {
                    switch strings.ToLower(attr.Key) {
                    case "rel":
                        relVal = strings.ToLower(attr.Val)
                    case "href":
                        hrefVal = attr.Val
                    }
                }
                // å¦‚æœ rel ä¸­åŒ…å« "icon" å°±è®¤ä¸ºå®ƒæ˜¯ç½‘ç«™å›¾æ ‡
                if strings.Contains(relVal, "icon") && hrefVal != "" {
                    if iconHref == "" {
                        iconHref = hrefVal
                    }
                }
            } else if tagName == "meta" {
                // å¤„ç† <meta ...> æ ‡ç­¾
                var propVal, contentVal string
                for _, attr := range n.Attr {
                    switch strings.ToLower(attr.Key) {
                    case "property":
                        propVal = strings.ToLower(attr.Val)
                    case "content":
                        contentVal = attr.Val
                    }
                }
                if propVal == "og:image" && contentVal != "" {
                    ogImage = contentVal
                }
            }
        }
        // ç»§ç»­éå†å­èŠ‚ç‚¹
        for c := n.FirstChild; c != nil; c = c.NextSibling {
            f(c)
        }
    }
    f(doc)

    if iconHref != "" {
        return makeAbsoluteURL(blogURL, iconHref)
    }
    if ogImage != "" {
        return makeAbsoluteURL(blogURL, ogImage)
    }
    // å¦‚æœéƒ½æ²¡æœ‰ï¼Œå°± fallback åˆ° /favicon.ico
    return fallbackFavicon(blogURL)
}

// fallbackFavicon è§£æå‡ºåŸŸåï¼Œç„¶åè¿”å› "scheme://host/favicon.ico"
func fallbackFavicon(blogURL string) string {
    u, err := url.Parse(blogURL)
    if err != nil {
        return ""
    }
    if u.Scheme == "" || u.Host == "" {
        return ""
    }
    return fmt.Sprintf("%s://%s/favicon.ico", u.Scheme, u.Host)
}

// makeAbsoluteURL å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
func makeAbsoluteURL(baseStr, refStr string) string {
    baseURL, err := url.Parse(baseStr)
    if err != nil {
        return refStr
    }
    refURL, err := url.Parse(refStr)
    if err != nil {
        return refStr
    }
    return baseURL.ResolveReference(refURL).String()
}

// checkURLAvailable é€šè¿‡ HEAD è¯·æ±‚æ£€æŸ¥æŸä¸ª URL æ˜¯å¦å¯ä»¥æ­£å¸¸è®¿é—®(è¿”å› 200)
func checkURLAvailable(urlStr string) (bool, error) {
    client := &http.Client{
        Timeout: 5 * time.Second, // è®¾ç½®è¶…æ—¶æ—¶é—´é˜²æ­¢é˜»å¡
    }
    req, err := http.NewRequest("HEAD", urlStr, nil)
    if err != nil {
        return false, err
    }
    resp, err := client.Do(req)
    if err != nil {
        return false, err
    }
    defer resp.Body.Close()
    return (resp.StatusCode == http.StatusOK), nil
}

/* ==================== GitHub æ—¥å¿—å†™å…¥ç›¸å…³å‡½æ•° ==================== */

// getGitHubFileSHA è·å–æŒ‡å®šä»“åº“å†…æŸä¸ªè·¯å¾„æ–‡ä»¶çš„ SHAï¼›è‹¥æ–‡ä»¶ä¸å­˜åœ¨åˆ™è¿”å›ç©º
func getGitHubFileSHA(ctx context.Context, token, owner, repo, path string) (string, error) {
    apiURL := fmt.Sprintf("https://api.github.com/repos/%s/%s/contents/%s", owner, repo, path)
    req, err := http.NewRequestWithContext(ctx, "GET", apiURL, nil)
    if err != nil {
        return "", err
    }
    req.Header.Set("Authorization", "Bearer "+token)

    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return "", err
    }
    defer resp.Body.Close()

    if resp.StatusCode == 404 {
        return "", nil
    }
    if resp.StatusCode != 200 {
        bodyBytes, _ := io.ReadAll(resp.Body)
        return "", fmt.Errorf("failed to get file %s, status: %d, body: %s", path, resp.StatusCode, string(bodyBytes))
    }

    var response struct {
        SHA string `json:"sha"`
    }
    if err = json.NewDecoder(resp.Body).Decode(&response); err != nil {
        return "", err
    }
    return response.SHA, nil
}

// getGitHubFileContent è·å–æŒ‡å®šæ–‡ä»¶çš„å®Œæ•´å†…å®¹å’Œ SHA
func getGitHubFileContent(ctx context.Context, token, owner, repo, path string) (string, string, error) {
    apiURL := fmt.Sprintf("https://api.github.com/repos/%s/%s/contents/%s", owner, repo, path)
    req, err := http.NewRequestWithContext(ctx, "GET", apiURL, nil)
    if err != nil {
        return "", "", err
    }
    req.Header.Set("Authorization", "Bearer "+token)

    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return "", "", err
    }
    defer resp.Body.Close()

    if resp.StatusCode == 404 {
        return "", "", nil
    }
    if resp.StatusCode != 200 {
        bodyBytes, _ := io.ReadAll(resp.Body)
        return "", "", fmt.Errorf("failed to get file %s, status: %d, body: %s", path, resp.StatusCode, string(bodyBytes))
    }

    var response struct {
        SHA     string `json:"sha"`
        Content string `json:"content"`
    }
    if err = json.NewDecoder(resp.Body).Decode(&response); err != nil {
        return "", "", err
    }

    decoded, err := base64.StdEncoding.DecodeString(response.Content)
    if err != nil {
        return "", "", err
    }
    return string(decoded), response.SHA, nil
}

// putGitHubFile åˆ›å»ºæˆ–æ›´æ–° GitHub ä»“åº“å†…çš„æ–‡ä»¶
func putGitHubFile(ctx context.Context, token, owner, repo, path, sha, content, commitMsg, committerName, committerEmail string) error {
    apiURL := fmt.Sprintf("https://api.github.com/repos/%s/%s/contents/%s", owner, repo, path)
    encoded := base64.StdEncoding.EncodeToString([]byte(content))

    payload := map[string]interface{}{
        "message": commitMsg,
        "content": encoded,
        "branch":  "main",
        "committer": map[string]string{
            "name":  committerName,
            "email": committerEmail,
        },
    }
    if sha != "" {
        payload["sha"] = sha
    }

    jsonBytes, err := json.Marshal(payload)
    if err != nil {
        return err
    }

    req, err := http.NewRequestWithContext(ctx, "PUT", apiURL, strings.NewReader(string(jsonBytes)))
    if err != nil {
        return err
    }
    req.Header.Set("Authorization", "Bearer "+token)
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return err
    }
    defer resp.Body.Close()

    if resp.StatusCode != 200 && resp.StatusCode != 201 {
        bodyBytes, _ := io.ReadAll(resp.Body)
        return fmt.Errorf("failed to put file %s, status: %d, body: %s",
            path, resp.StatusCode, string(bodyBytes))
    }
    return nil
}

// deleteGitHubFile åˆ é™¤ GitHub ä»“åº“å†…çš„æ–‡ä»¶
func deleteGitHubFile(ctx context.Context, token, owner, repo, path, sha, committerName, committerEmail string) error {
    apiURL := fmt.Sprintf("https://api.github.com/repos/%s/%s/contents/%s", owner, repo, path)

    payload := map[string]interface{}{
        "message":   "Delete old log file",
        "sha":       sha,
        "branch":    "main",
        "committer": map[string]string{"name": committerName, "email": committerEmail},
    }
    jsonBytes, err := json.Marshal(payload)
    if err != nil {
        return err
    }

    req, err := http.NewRequestWithContext(ctx, "DELETE", apiURL, strings.NewReader(string(jsonBytes)))
    if err != nil {
        return err
    }
    req.Header.Set("Authorization", "Bearer "+token)
    req.Header.Set("Content-Type", "application/json")

    client := &http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return err
    }
    defer resp.Body.Close()

    if resp.StatusCode != 200 {
        bodyBytes, _ := io.ReadAll(resp.Body)
        return fmt.Errorf("failed to delete file %s, status: %d, body: %s",
            path, resp.StatusCode, string(bodyBytes))
    }
    return nil
}

// listGitHubDir åˆ—å‡º GitHub ä»“åº“æŸç›®å½•ä¸‹çš„æ–‡ä»¶ä¸ä¿¡æ¯
func listGitHubDir(ctx context.Context, token, owner, repo, dir string) ([]struct {
    Name string `json:"name"`
    SHA  string `json:"sha"`
    Type string `json:"type"`
}, error) {
    apiURL := fmt.Sprintf("https://api.github.com/repos/%s/%s/contents/%s", owner, repo, dir)
    req, err := http.NewRequestWithContext(ctx, "GET", apiURL, nil)
    if err != nil {
        return nil, err
    }
    req.Header.Set("Authorization", "Bearer "+token)
    client := &http.Client{}

    resp, err := client.Do(req)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    if resp.StatusCode == 404 {
        return nil, nil
    }
    if resp.StatusCode != 200 {
        bodyBytes, _ := io.ReadAll(resp.Body)
        return nil, fmt.Errorf("failed to list dir %s, status: %d, body: %s",
            dir, resp.StatusCode, string(bodyBytes))
    }

    var files []struct {
        Name string `json:"name"`
        SHA  string `json:"sha"`
        Type string `json:"type"`
    }
    if err := json.NewDecoder(resp.Body).Decode(&files); err != nil {
        return nil, err
    }
    return files, nil
}

// appendLog å‡½æ•°ï¼šç”¨äºå°†æ—¥å¿—å†…å®¹å†™å…¥ GitHub ä»“åº“çš„ logs/YYYY-MM-DD.log æ–‡ä»¶ï¼Œå¹¶æ¸…ç†7å¤©å‰çš„æ—¥å¿—
func appendLog(ctx context.Context, rawLogContent string) error {
    token := os.Getenv("TOKEN")
    githubUser := os.Getenv("NAME")
    repoName := os.Getenv("REPOSITORY")
    owner := githubUser
    repo := repoName

    committerName := githubUser
    committerEmail := githubUser + "@users.noreply.github.com"

    // æ—¥å¿—æ–‡ä»¶åï¼šlogs/2025-03-10.log (ç¤ºä¾‹)
    dateStr := time.Now().Format("2006-01-02")
    logPath := filepath.Join("logs", dateStr+".log")

    // 1. è·å–æ—§å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
    oldContent, oldSHA, err := getGitHubFileContent(ctx, token, owner, repo, logPath)
    if err != nil {
        return err
    }

    // 2. åœ¨æ–°å†…å®¹æ¯è¡Œå‰é¢åŠ ä¸Šæ—¶é—´æˆ³ï¼ˆåŸä»£ç äº¦æ˜¯å¦‚æ­¤ï¼Œè¿™é‡Œä¿æŒï¼‰
    var sb strings.Builder
    timestamp := time.Now().Format("2006-01-02 15:04:05")
    lines := strings.Split(rawLogContent, "\n")
    for _, line := range lines {
        line = strings.TrimSpace(line)
        if line == "" {
            continue
        }
        sb.WriteString(fmt.Sprintf("[%s] %s\n", timestamp, line))
    }
    newLogSegment := sb.String()
    newContent := oldContent + newLogSegment

    // 3. ä¸Šä¼ æ›´æ–°åˆ° GitHub
    err = putGitHubFile(ctx, token, owner, repo, logPath, oldSHA, newContent,
        "Update log: "+dateStr, committerName, committerEmail)
    if err != nil {
        return err
    }

    // 4. åˆ é™¤ 7 å¤©å‰çš„æ—¥å¿—æ–‡ä»¶
    return cleanOldLogs(ctx, token, owner, repo, committerName, committerEmail)
}

// cleanOldLogs åˆ é™¤ 7 å¤©å‰çš„æ—¥å¿—æ–‡ä»¶
func cleanOldLogs(ctx context.Context, token, owner, repo, committerName, committerEmail string) error {
    files, err := listGitHubDir(ctx, token, owner, repo, "logs")
    if err != nil {
        return nil
    }
    sevenDaysAgo := time.Now().AddDate(0, 0, -7)

    for _, f := range files {
        if f.Type != "file" {
            continue
        }
        matched, _ := regexp.MatchString(`^\d{4}-\d{2}-\d{2}\.log$`, f.Name)
        if !matched {
            continue
        }
        dateStr := strings.TrimSuffix(f.Name, ".log")
        t, err := time.Parse("2006-01-02", dateStr)
        if err != nil {
            continue
        }
        if t.Before(sevenDaysAgo) {
            path := filepath.Join("logs", f.Name)
            delErr := deleteGitHubFile(ctx, token, owner, repo, path, f.SHA, committerName, committerEmail)
            if delErr != nil {
                fmt.Printf("åˆ é™¤æ—§æ—¥å¿— %s å¤±è´¥: %v\n", f.Name, delErr)
            } else {
                fmt.Printf("å·²åˆ é™¤æ—§æ—¥å¿— %s\n", f.Name)
            }
        }
    }
    return nil
}

/* ==================== å·¥å…·å‡½æ•°ï¼šéæ³•å­—ç¬¦æ¸…æ´— / RSSåˆ—è¡¨è·å– / COSä¸Šä¼  ==================== */

// sanitizeXML å°†å­—ç¬¦ä¸²ä¸­çš„éæ³• XML å­—ç¬¦è¿‡æ»¤æ‰ï¼ˆæˆ–æ›¿æ¢ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
func sanitizeXML(input string) string {
    var sb strings.Builder
    for _, r := range input {
        // è¿‡æ»¤æ‰é™¤ \t, \n, \r ä»¥å¤–çš„å°äº0x20çš„æ§åˆ¶å­—ç¬¦
        if (r == 0x9) || (r == 0xA) || (r == 0xD) || (r >= 0x20) {
            sb.WriteRune(r)
        } else {
            // è·³è¿‡æ— æ•ˆæ§åˆ¶å­—ç¬¦
        }
    }
    return sb.String()
}

// fetchRSSLinks ä»ç»™å®š URL çš„æ–‡æœ¬æ–‡ä»¶é€è¡Œè¯»å– RSS é“¾æ¥
func fetchRSSLinks(rssListURL string) ([]string, error) {
    resp, err := http.Get(rssListURL)
    if err != nil {
        return nil, err
    }
    defer resp.Body.Close()

    if resp.StatusCode != 200 {
        return nil, fmt.Errorf("status code: %d", resp.StatusCode)
    }
    data, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, err
    }

    var links []string
    for _, line := range strings.Split(string(data), "\n") {
        line = strings.TrimSpace(line)
        if line != "" {
            links = append(links, line)
        }
    }
    return links, nil
}

// uploadToCos ä½¿ç”¨ cos-go-sdk-v5ï¼Œå°† data.json è¦†ç›–ä¸Šä¼ åˆ°å¯¹åº” Bucket
func uploadToCos(ctx context.Context, secretID, secretKey, dataURL string, data []byte) error {
    u, err := url.Parse(dataURL)
    if err != nil {
        return err
    }
    baseURL := &cos.BaseURL{
        BucketURL: &url.URL{
            Scheme: u.Scheme,
            Host:   u.Host,
        },
    }
    client := cos.NewClient(baseURL, &http.Client{
        Transport: &cos.AuthorizationTransport{
            SecretID:  secretID,
            SecretKey: secretKey,
        },
    })
    key := strings.TrimPrefix(u.Path, "/")

    _, err = client.Object.Put(ctx, key, strings.NewReader(string(data)), nil)
    return err
}

/* ==================== æ ¸å¿ƒæŠ“å–é€»è¾‘ + ä¸»å‡½æ•° ==================== */

// fetchAndParseRSS å¯¹å•ä¸ª RSS é“¾æ¥è¿›è¡ŒæŠ“å–ï¼Œå¹¶ç”¨ sanitizeXML è¿‡æ»¤éæ³•å­—ç¬¦åå†è°ƒç”¨ gofeed è§£æ
func fetchAndParseRSS(rssLink string, fp *gofeed.Parser) (*gofeed.Feed, error) {
    // 1. å‘é€è¯·æ±‚
    resp, err := http.Get(rssLink)
    if err != nil {
        return nil, fmt.Errorf("è¯·æ±‚å¤±è´¥: %v", err)
    }
    defer resp.Body.Close()

    // 2. è¯»å– Body
    rawBytes, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, fmt.Errorf("è¯»å–å¤±è´¥: %v", err)
    }

    // 3. æ¸…æ´—éæ³•å­—ç¬¦
    cleaned := sanitizeXML(string(rawBytes))

    // 4. äº¤ç»™ gofeed è§£æ
    feed, err := fp.ParseString(cleaned)
    if err != nil {
        return nil, fmt.Errorf("è§£æ RSS å¤±è´¥: %v", err)
    }
    return feed, nil
}

func main() {
    // åˆ›å»ºä¸€ä¸ªä¸Šä¸‹æ–‡ï¼Œå¯åœ¨æ•´ä¸ªæµç¨‹ä¸­ä½¿ç”¨
    ctx := context.Background()

    // ä»ç¯å¢ƒå˜é‡è¯»å–æ‰€éœ€é…ç½®
    secretID := os.Getenv("TENCENT_CLOUD_SECRET_ID")   // è…¾è®¯äº‘ COS SecretID
    secretKey := os.Getenv("TENCENT_CLOUD_SECRET_KEY") // è…¾è®¯äº‘ COS SecretKey
    rssListURL := os.Getenv("RSS")                     // å­˜æ”¾ RSS é“¾æ¥çš„TXTæ–‡ä»¶åœ°å€
    dataURL := os.Getenv("DATA")                       // data.json è¦ä¸Šä¼ åˆ°çš„ COS è·¯å¾„
    defaultAvatar := os.Getenv("DEFAULT_AVATAR")       // æ²¡æœ‰å¯ç”¨å¤´åƒæ—¶çš„é»˜è®¤å¤´åƒ

    // å¦‚æœå…³é”®ä¿¡æ¯ä¸å…¨ï¼Œåˆ™å†™æ—¥å¿—å¹¶é€€å‡º
    if secretID == "" || secretKey == "" || rssListURL == "" || dataURL == "" {
        _ = appendLog(ctx, "[ERROR] ç¯å¢ƒå˜é‡ç¼ºå¤±ï¼Œè¯·æ£€æŸ¥ TENCENT_CLOUD_SECRET_ID/TENCENT_CLOUD_SECRET_KEY/RSS/DATA æ˜¯å¦å·²é…ç½®ã€‚")
        return
    }
    if defaultAvatar == "" {
        _ = appendLog(ctx, "[WARN] æœªè®¾ç½® DEFAULT_AVATARï¼Œå°†ä¼šå¯¼è‡´æ— æ³•è®¿é—®å¤´åƒæ—¶å‡ºç°ç©ºå­—ç¬¦ä¸²ã€‚")
    }

    // 1. æ‹‰å– RSS åˆ—è¡¨
    rssLinks, err := fetchRSSLinks(rssListURL)
    if err != nil {
        _ = appendLog(ctx, fmt.Sprintf("[ERROR] æ‹‰å– RSS é“¾æ¥å¤±è´¥: %v", err))
        return
    }
    if len(rssLinks) == 0 {
        _ = appendLog(ctx, "[WARN] RSS åˆ—è¡¨ä¸ºç©ºï¼Œæ²¡æœ‰éœ€è¦æŠ“å–çš„é“¾æ¥ã€‚")
        return
    }

    // å¹¶å‘æ§åˆ¶
    maxGoroutines := 10
    sem := make(chan struct{}, maxGoroutines)
    var wg sync.WaitGroup

    // å­˜æ”¾ç»“æœ
    resultChan := make(chan feedResult, len(rssLinks))
    fp := gofeed.NewParser()

    // 2. å¹¶å‘æŠ“å–
    for _, link := range rssLinks {
        link = strings.TrimSpace(link)
        if link == "" {
            continue
        }
        wg.Add(1)
        sem <- struct{}{} // å ç”¨ä¸€ä¸ªå¹¶å‘æ§½

        go func(rssLink string) {
            defer wg.Done()
            defer func() { <-sem }() // é‡Šæ”¾å¹¶å‘æ§½

            var fr feedResult
            fr.FeedLink = rssLink

            feed, err := fetchAndParseRSS(rssLink, fp)
            if err != nil {
                fr.Err = err
                resultChan <- fr
                return
            }
            if feed == nil || len(feed.Items) == 0 {
                fr.Err = fmt.Errorf("è¯¥è®¢é˜…æ²¡æœ‰å†…å®¹")
                resultChan <- fr
                return
            }

[thinking]

            // è·å–å¤´åƒ
            avatarURL := getFeedAvatarURL(feed)
            fr.Article = &Article{
                BlogName: feed.Title,
            }

            // æ ¡éªŒå¤´åƒ
            if avatarURL == "" {
                fr.Article.Avatar = ""
            } else {
                ok, _ := checkURLAvailable(avatarURL)
                if !ok {
                    fr.Article.Avatar = "BROKEN"
                } else {
                    fr.Article.Avatar = avatarURL
                }
            }

            // åªå–æœ€æ–°çš„ä¸€ç¯‡
            latest := feed.Items[0]
            fr.Article.Title = latest.Title
            fr.Article.Link = latest.Link

            // å°è¯•è§£æå‘å¸ƒæ—¶é—´
            pubTime := time.Now()
            if latest.PublishedParsed != nil {
                pubTime = *latest.PublishedParsed
            } else if latest.Published != "" {
                if t, e := parseTime(latest.Published); e == nil {
                    pubTime = t
                }
            }
            fr.ParsedTime = pubTime
            fr.Article.Published = pubTime.Format("02 Jan 2006") // ä¾‹å¦‚ "09 Mar 2025"

            resultChan <- fr
        }(link)
    }

    // ç­‰å¾…æ‰€æœ‰ goroutine å®Œæˆ
    go func() {
        wg.Wait()
        close(resultChan)
    }()

    /* ç»Ÿè®¡ä¿¡æ¯ç›¸å…³çš„ä¸´æ—¶ç»“æ„ */
    var itemsWithTime []struct {
        article Article
        t       time.Time
        link    string
    }

    // è®°å½•å„ç§å¯èƒ½çš„é—®é¢˜ï¼Œç”¨äºæœ€ç»ˆå†™æ—¥å¿—
    var parseFails []string       // RSS è§£æå¤±è´¥ / è¯·æ±‚å¤±è´¥
    var feedEmpties []string      // æ— å†…å®¹
    var noAvatarList []string     // å¤´åƒå­—æ®µä¸ºç©º
    var brokenAvatarList []string // å¤´åƒæ— æ³•è®¿é—®
    var successCount int          // æˆåŠŸæŠ“å–è®¡æ•°

    // 3. æ”¶é›†ç»“æœ
    for r := range resultChan {
        if r.Err != nil {
            // åˆ¤æ–­æ˜¯è§£æå¤±è´¥è¿˜æ˜¯ feed æ²¡å†…å®¹
            if strings.Contains(r.Err.Error(), "è§£æ RSS å¤±è´¥") || strings.Contains(r.Err.Error(), "è¯·æ±‚å¤±è´¥") {
                parseFails = append(parseFails, r.FeedLink)
            } else if strings.Contains(r.Err.Error(), "æ²¡æœ‰å†…å®¹") {
                feedEmpties = append(feedEmpties, r.FeedLink)
            }
            continue
        }

        // æ­£å¸¸æ‹¿åˆ°Article
        successCount++

        // æ£€æŸ¥å¤´åƒ
        if r.Article.Avatar == "" {
            noAvatarList = append(noAvatarList, r.FeedLink)
            r.Article.Avatar = defaultAvatar
        } else if r.Article.Avatar == "BROKEN" {
            brokenAvatarList = append(brokenAvatarList, r.FeedLink)
            r.Article.Avatar = defaultAvatar
        }

        // æ”¶é›†åˆ°æœ€ç»ˆé›†åˆé‡Œ
        itemsWithTime = append(itemsWithTime, struct {
            article Article
            t       time.Time
            link    string
        }{
            article: *r.Article,
            t:       r.ParsedTime,
            link:    r.FeedLink,
        })
    }

    // 4. æŒ‰å‘å¸ƒæ—¶é—´â€œå€’åºâ€
    sort.Slice(itemsWithTime, func(i, j int) bool {
        return itemsWithTime[i].t.After(itemsWithTime[j].t)
    })

    // ç»„è£…åˆ°æœ€ç»ˆè¾“å‡º
    var allItems []Article
    for _, v := range itemsWithTime {
        allItems = append(allItems, v.article)
    }

    // 5. ç»„è£… JSON
    allData := AllData{
        Items:   allItems,
        Updated: time.Now().Format("2006å¹´01æœˆ02æ—¥ 15:04:05"), // ä¸­æ–‡æ ¼å¼æ—¶é—´
    }
    jsonBytes, err := json.MarshalIndent(allData, "", "  ")
    if err != nil {
        _ = appendLog(ctx, fmt.Sprintf("[ERROR] JSON åºåˆ—åŒ–å¤±è´¥: %v", err))
        return
    }

    // 6. ä¸Šä¼  data.json åˆ°è…¾è®¯äº‘ COS
    err = uploadToCos(ctx, secretID, secretKey, dataURL, jsonBytes)
    if err != nil {
        _ = appendLog(ctx, fmt.Sprintf("[ERROR] ä¸Šä¼  data.json åˆ° COS å¤±è´¥: %v", err))
        return
    }

    // ====================== è¿˜åŸâ€œä¹‹å‰çš„æ—¥å¿—è¾“å‡ºæ ¼å¼â€åœ¨æ­¤å¤„ ======================
    var sb strings.Builder
    sb.WriteString("æœ¬æ¬¡è®¢é˜…æŠ“å–ç»“æœç»Ÿè®¡å¦‚ä¸‹ï¼š\n")

    // ç»Ÿè®¡æˆåŠŸæ•°
    sb.WriteString(fmt.Sprintf("âœ… æˆåŠŸæŠ“å– %d æ¡è®¢é˜…ã€‚\n", successCount))

    // è§£æ/è¯·æ±‚å¤±è´¥ç»Ÿè®¡
    if len(parseFails) > 0 {
        sb.WriteString(fmt.Sprintf("âŒ æœ‰ %d æ¡è®¢é˜…è§£æå¤±è´¥æˆ–è¯·æ±‚å¤±è´¥ï¼š\n", len(parseFails)))
        for _, l := range parseFails {
            sb.WriteString("  - " + l + "\n")
        }
    }

    // æ— å†…å®¹
    if len(feedEmpties) > 0 {
        sb.WriteString(fmt.Sprintf("âš ï¸ æœ‰ %d æ¡è®¢é˜…ä¸ºç©ºï¼š\n", len(feedEmpties)))
        for _, l := range feedEmpties {
            sb.WriteString("  - " + l + "\n")
        }
    }

    // å¤´åƒå­—æ®µä¸ºç©º
    if len(noAvatarList) > 0 {
        sb.WriteString(fmt.Sprintf("ğŸ–¼ï¸ æœ‰ %d æ¡è®¢é˜…å¤´åƒå­—æ®µä¸ºç©ºï¼Œå·²ä½¿ç”¨é»˜è®¤å¤´åƒï¼š\n", len(noAvatarList)))
        for _, l := range noAvatarList {
            sb.WriteString("  - " + l + "\n")
        }
    }

    // å¤´åƒæ— æ³•è®¿é—®
    if len(brokenAvatarList) > 0 {
        sb.WriteString(fmt.Sprintf("ğŸ–¼ï¸ æœ‰ %d æ¡è®¢é˜…å¤´åƒæ— æ³•è®¿é—®ï¼Œå·²ä½¿ç”¨é»˜è®¤å¤´åƒï¼š\n", len(brokenAvatarList)))
        for _, l := range brokenAvatarList {
            sb.WriteString("  - " + l + "\n")
        }
    }

    // è‹¥æ‰€æœ‰é”™è¯¯éƒ½æ²¡æœ‰
    if len(parseFails) == 0 && len(feedEmpties) == 0 && len(noAvatarList) == 0 && len(brokenAvatarList) == 0 {
        sb.WriteString("æ²¡æœ‰ä»»ä½•è­¦å‘Šæˆ–é”™è¯¯ï¼Œä¸€åˆ‡æ­£å¸¸ã€‚\n")
    }

    // å†™å…¥æ—¥å¿—
    _ = appendLog(ctx, sb.String())
}